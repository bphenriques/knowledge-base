'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/knowledge-base/concurrency/actor-model/','title':"Actor Model",'section':"Concurrency",'content':" Referred in\n Lightbend Academy   In the context of Reactive Systems, Actor model is a reactive tool, a paradigm that:\n Message driven - All communication between actors is done with async non-blocking messages. Abstractions provide elasticity and resiliency.  Akka uses the actor model - https://doc.akka.io/docs/akka/current/typed/guide/actors-intro.html?language=scala\nFundamental #   All computation occurs inside of the actor. Each actor has an address. Actors only communicate through asyncronous messages.  The message driven system provides location transparency, i.e., the technique remainins the same regardless of where the actors are. This allows better resiliency and elastic (hmm.. questions on this bit). This is different from \u0026ldquo;Transparent remoting\u0026rdquo; as this hides potential networking issues while making it seem like local calls. Location transparency makes the opposite which is makes local calls seem like remote calls, therefore whoever uses is aware that there are potential failures.\n"});index.add({'id':1,'href':'/knowledge-base/data-processing/apache-spark/','title':"Apache Spark",'section':"Data Processing",'content':"#ROAM_TAGS: data\nGlossary #   RDD - Resilient Distributed Datasets  "});index.add({'id':2,'href':'/knowledge-base/monitoring/bug-management/','title':"Bug Management",'section':"Monitoring",'content':"Some personal notes on simplifying the process so that one can focus on getting back to the other tasks at hand.\nOn Reporting Bugs #   Focus on the impact for the client. You do not need to debug right away. You do not need to establish the timeline - The report can solely include the context. The person assigned to the issue will pick on the context provided in the ticket and explore.  "});index.add({'id':3,'href':'/knowledge-base/system-design/consistency_and_availability/','title':"Consistency And Availability",'section':"System Design",'content':"Scalability #  It can meets increases in demand while remaining responsive.\nThis is different from performance. Performance optimizes response time (latency) while scalability optimizes ability to handle load. Requests per second actually measures both but we do not know which aspect was improved.\nNote Scalability is not the number of requests qwe can handle a in a given period of time (req/sec) but he number of requests itself (load).\nIf x axis is number of requests (Load) and y axis is response time. Improving performance leads to decrease in the y axis. Improving scalability means a shift on the x axis meaning that we can handle more requests with the same response time.\nStill confused as if I improve performance I should free up resources to handle more requests..\nReactive Microservices focus on improving scalability.\nConsistency: #  All members of the system have the same view or state. This does not factors time.\nEventual Consistency #  Guarantees that, in the absence of new updates, all accesses to a specific piece of data will eventually return the most recent data.\nDifferent forms:\n Eventual Consistency Causal Consistency Sequential Conssitency others  E.g., Source control are eventually consistent. All the code reading is potentially out-of-date and a merge operations is relied upon to bring the local state back to speed.\nTODO: Check each one #  Strong Consistency #  An update to a piece of data needs agreement from all nodes before it becomes visible.\nPhysically it is impossible therefore we simulate: Locks that introduce overhead in the form of contention. Now it becomes a single resource which eliminates the distributed nature. Tying the distributed problem to a non-distributed resource.\nTraditionally, monoliths are based around strong consistency.\nEffects of contention #  Definition: Any two things that contend for a single limited resource and only one will win and the other will be forced to wait.\nAs the number of resources disputing for the resource, more time time it will take to finally free up the resources.\n   Amdahl\u0026rsquo;s law\nIn short, contention limits paralelization.\nDefines the maximum improvement gaines by parallel procesing. Improvements from paralelization are limited to the code that can be paralelized. Contention limits such paralism reducing the advantages of the improvements. Does not matter as long as the contention exist.\n     Coherence Delay\nDefinition: Time it takes for synchronization to complete on a distributed systems - My definition following below notes:\nSyncronization is done using crosstalk or gossip - Each system sends messages to each other node informing of any state changes. The time it takes for the cynscronization to complete is called Coeherency Delay.\nIncreasing the number of nodes increases the delay.\n     Gunther\u0026rsquo;s Universal Scalability Law\nIncreasing concurrency can cause negative resutrns due to contention and coherency delay.\nPicks from Amdahl\u0026rsquo;s law. In addition to contention, it accounts for coeherency delay.\nAs the system scales up, the cost to coordinate between nodes exceeds any benefits.\n     Laws of scalability\nBoth these laws demonstrate that linear scalability is almost always unachivable. Such is only possible if the system lieve in total isolation.\n     Reactive Systems\nReduce contention by:\n Isolating locks Eliminating transactions Avoiding blocking operations  Mitigate coherency delays by:\n Embracing Eventual Consistency Building in Autonmy  This allows for higher scalability as we reduce or eliminate these factors.\n  CAP Theorem #  States that a distributed system cannnot provide more than than two of the following:\n Consistency Availability Partition Tolerance  One has to pick one of the following combinations:\n (CP) Consistent and Partition Tolerance (AP) Available and Partition Tolerance.  In practice, they may claim CP/AP except for some edge-cases. It is a balance.\nPartition Tolerance #  The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network.\nThey can occur due to:\n Problems in the network. When a node goes down.  May be short or long lived.\nTwo options:\n (AP) Sacrifice Consistency: Allow writes to both sides of the partition. This require merging the data in order to restore consistency. (CP) Sacrifice Availability: Disabling or terminating on side of the partitions. During this, some or all of your system will be unavailable.  Sharding as a way to have strong consistency #  Limit the scope of the contention and reduce crosstalk. Is applied within the application. It is not the same type of sharding used in some databases, the technique is similar though.\nAllows strong consistency.\nPartitions entities (or Actors) in the domain according to their id.\nGroups of entities are called a shard and each entity only exists in one shard.\nEach shard exists in only one location. This fact eliminates the distributed systems problem.\nThe entity acts as a consistency boundary.\nIn order for this to work, we need to have a coordinator that ensures that traffic for a particular entity is routed to the correct location. The coordinator uses the ID to calculate the appropriate shard.\nAggregate Roots are good candidate for sharding.\nIt is important to have a balanced shards and that requires a good sharding key - UUIDs or hashcodes. Poor key selections will result in hotspots.\nRule of thumb: 10x as many shards as nodes.\nAkka provides this as a means to distribute actors across a cCLuster in a shared setup. Lagom persistent entities levarage akka cluster sharding to distribute the entities across the cluster.\nWhat about resharding? when a system goes down\u0026hellip;\nSharding allows a great caching solution as:\n We can store the cache results after writing to the database Databases is effectively write-only which can speed up things We only consult the cache during reads. Begs the question: How many items and what is the TTL? Well.. it for certain reduces the read on the DB but that is not forever unless we have infinite memory.  Effects #   Does not eliminate contention. It solely isolates to a single entity. The router/coordinator represents a source of contention as well. A shareded system minimizes contention by:  Limiting the amounf of work the router/coordinator performs - By storing where the shard is after asking the coordinator - How to invalidate that cache due to failures? Isolates contention to individual entities    Scalability is doen by distributing the shards over mode machines. Strong consistency is achiaved by isolating operations to a specific entity. Careful choice of shard keys is important to maintain a good scalability.\nFailure #  Sharding sacrifices availability. Once a shard goes down, there will be a period of time where it is unavailable and wil migrate to another node eventually.\nCRDTs provide a availability solution based on async replication #  Conflict-free Replicated Data\nOn the application level.\nHighly available and eventually consistent.\nSpecially designed data type.\nUpdates are applied on one replica and then copied async.\nUdpdates are merged to determine the final state.\nTwo types:\n CvRDT - Convergent Replicated Data Type copy state between replicas. Requires a merge operation that understands how to combine two states. These operations must be: commutative, associative and idempotent. CmRDT - Commutative Replicated Data Types. These copy operations isntead of state.  "});index.add({'id':4,'href':'/knowledge-base/system-design/distribute_systems/','title':"Distributed Systems",'section':"System Design",'content':"Definition: Systems that are separated by space.\nIssue: Consistency. By the time the receiver receives the state of the sender, the state may have already changed!\n"});index.add({'id':5,'href':'/knowledge-base/system-design/domain_driven_design/','title':"Domain Driven Design",'section':"System Design",'content':" Referred in\n Microservices   See raw in Lightbend Academy\nUseful for modelling use-cases before attempting to implement it whether in Software or mere Diagrams.\nSubject-Verb-Object notation #  Allows having a consistent way to phrase activies our events in the domain.\nExample: Host checks current reservation.\n Subject: Host Verb: Checks Object: Reservation  Note that \u0026ldquo;current\u0026rdquo; can be seen as a modifier.\nSometimes there may be multiple objects. E.g., \u0026ldquo;Bartender collects Payment for a Drink Order\u0026rdquo;:\n Both are objects \u0026ldquo;Payment\u0026rdquo; is a direct object. \u0026ldquo;Drink Order\u0026rdquo; is a indirect object.  Regardless, diferentiation is not that relevant.\nBounded Context #  Each one have unique domain concepts and not all contexts are compatible with others.\nAnti-Corruption Layer #  Solves issues where coupling starts. This layer leaves right next to the bounded context to avoid leaking info from/to that bounded context.\nTypical example: Let\u0026rsquo;s put everything in the same bag.\nWhat happens is that we have a layer responsible for translating similar concepts from one bounded context to another.\nHow to implement: Abstract interface as it represents the contract in its purest way without compromising - Sometimes abstractions are too much indirection but do understand. :shrug:\nactor User control \u0026quot;Anti Corruption Layer\u0026quot; as ACL entity Component User -\u0026gt; ACL: Process X ACL -\u0026gt; ACL: Translate concept X to Y ACL -\u0026gt; Component: Process Y Component --\u0026gt; ACL: Z ACL --\u0026gt; User: Z This is also useful for legacy systems. In this case a Anti Corruption Layer would be preferable on either end.\nTODO Simpler diagram (if plantuml is able to generate one and I understand how..) #  Context Map #  Are a way of of visualizating Bounded contexts and the relationships between them.\n[Bounded Context A] -\u0026gt; [Bounded Context B] [Bounded Context A] -\u0026gt; [Bounded Context C] [Bounded Context B] -\u0026gt; [Bounded Context C] [Bounded Context C] -\u0026gt; [Bounded Context D]  Arrows represent dependencies. Lines may be labelled to indicate the nature of the relationship.  TODO Discovery Process using Event Storming #  Types of Domain Activities #   Command: A request yet to happen and can be rejected. Usually delivered to a specific destination and changes the state of the domain. Events: Action that happened in the past. Hence they can not be rejected. Often broadcast to many destinations. Record a change to the state of the domain, often the result of a command (what are the alternatives?). Query: Requestfor information about the domain. Usually delievered to a specific destination. Do not change the state of the domain.  All of these represent the types of messages in a Reactive System and form the API for a Bounded Context.\nDomain Objects #   Value objects: Defined by its attribute. Immuatable. Messages in Reactive Systems are implemented as Value Objects. Entity: Defined by an unique identity. The fields may change but not its identitity. Are the soruce of truth - Actors in Akka or Entitities in Lagom (hopefully will click later)  Monolith- Aggregate: Collection of domain objects bound to a root entity:\n Example: Person (Aggregate Root), Name (Aggregate), Address (Aggregate). Transactions should not span multiple aggregate roots. The Aggregate Root may change between bounded contexts. Aggregate Root == Root Entity. Good cadnidates for distribution in Reactive Systems. Question: How to determine?  Is the entity involved in more operations in the same bounded context? Does it make sense deleting other entities when this one is deleted? Will a single transaction span multiple entities?    Domain Abstractiosn #  Services #  Busines Logic encapsulated. Should be stateless otherwise they become an entity or a value object.\nShould be fairly thin.\nFactories #  Constructing domain object may not be trivial as they may have to access external resources (DBs, files, REst APIs, etc).\nRepositories #  Similar to factories but used to get or modify existing objects. They work often over databases but can work with files or Rest Apis (I actually prefer \u0026ldquo;Gateways\u0026rdquo; for Rest APIs).\nNote: Factories and Repositories can be the same in practice.\nHexagonal Architecutre #  Is not directly related with domain driven design but is very compatible.\nDomain is at the core and is at teh center becoming the architectural focus. Then there are ports to communicate with the domain exposed as API for the domain. INfrastructure contains adapters that map to the ports.\nLike an Onion\n Domain  API - The ports Infrastructure - Adapts incoming and outgoing traffic in to the ports.    Outer layers depends on inner layers. And inner layers have no knowledge of other layers.\n:thinking: This does not seem different from the typical layered design with DB -\u0026gt; Services -\u0026gt; API\nEnsures proper spearation of infrastructure from domain.\nThese layers may be modelled through packages or projects. Details are not important. The important thing is to make the domain portable.\nWould like a concrete example on how it really differents from the N tiered design.\n"});index.add({'id':6,'href':'/knowledge-base/learning/hands_on_scala_programming/','title':"Hands-on Scala Programming",'section':"Learning",'content':"Follows my notes on the Haoyi Li.\u0026rsquo;s book: \u0026ldquo;Hands-on Scala Programming\u0026rdquo;.\nAs an experiment, I coding directly in the org-mode file using Babel to execute the Scala blocks:\nTODO Some introduction #   Point to dotfiles Point to the Babel package  Notes #   Lack of auto-complete when writing here. Compilation errors are hard to track. Workaround is to open a separate buffer with the ammonite REPL console. For sure will have to move to a dedicated project once I use Mill. Or maybe not.  Exercises 3.5 #  3.63 #   “Write a short program that prints each number from 1 to 100 on a new line.\nFor each multiple of 3, print \u0026ldquo;Fizz\u0026rdquo; instead of the number.\nFor each multiple of 5, print \u0026ldquo;Buzz\u0026rdquo; instead of the number.\nFor numbers which are multiples of both 3 and 5, print \u0026ldquo;FizzBuzz\u0026rdquo; instead of the number.”\n   \u0026ldquo;Define a def flexibleFizzBuzz method that takes a String =\u0026gt; Unit callback function as its argument, and allows the caller to decide what they want to do with the output. The caller can choose to ignore the output, println the output directly, or store the output in a previously-allocated array they already have handy.”\n def flexibleFizBuzz(callback: String =\u0026gt; Unit) { (1 to 100).foreach { i =\u0026gt; if (i % 3 == 0 \u0026amp;\u0026amp; i % 5 == 0) callback(\u0026#34;FizzBuzz\u0026#34;) else if (i % 3 == 0) callback(\u0026#34;Fizz\u0026#34;) else if (i % 5 == 0) callback(\u0026#34;Buzz\u0026#34;) else callback(i.toString) } } flexibleFizBuzz(s =\u0026gt; println(s)) 3.64 #   “Write a recursive method printMessages that can receive an array of Msg class instances, each with an optional parent ID, and use it to print out a threaded fashion. That means that child messages are print out indented underneath their parents, and the nesting can be arbitrarily deep.”\n  I assume that the items are ordered by their identifier which is incremental with each new message.   class Msg(val id: Int, val parent: Option[Int], val txt: String) def printMessages(messages: Array[Msg]) { val padding = 2 def printMessages(index: Int, msgLevel: Map[Int, Int]) { if (index \u0026lt; messages.length) { val message = messages(index) val level = message.parent match { case Some(parent) =\u0026gt; msgLevel.getOrElse(parent, 0) + 1 case None =\u0026gt; 0 } println(\u0026#34; \u0026#34; * level * padding + message.txt) printMessages(index + 1, msgLevel + (message.id -\u0026gt; level)) } } printMessages(index = 0, msgLevel = Map()) } printMessages(Array( new Msg(0, None, \u0026#34;Hello\u0026#34;), new Msg(1, Some(0), \u0026#34;World\u0026#34;), new Msg(2, None, \u0026#34;I am Cow\u0026#34;), new Msg(3, Some(2), \u0026#34;Hear me moo\u0026#34;), new Msg(4, Some(2), \u0026#34;Here I stand\u0026#34;), new Msg(5, Some(2), \u0026#34;I am Cow\u0026#34;), new Msg(6, Some(5), \u0026#34;Here me moo, moo\u0026#34;) )) "});index.add({'id':7,'href':'/knowledge-base/jvm/jackson/','title':"Jackson",'section':"JVM",'content':"Sane Settings #  After working a while with this I want to register these sane defaults:\nconfigure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, true) configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) FAIL_ON_NULL_FOR_PRIMITIVES #  Setting FAIL_ON_NULL_FOR_PRIMITIVES forces clients to explicitely provide all values including primitives. Consider the following POJO:\ndata class Foo(bar: Boolean) Without the setting, a payload such as { } would render ~Foo(bar=false)~ despite the lack of default value. Given this, to guarantee consistency between the source-code and the external contract, I advise enabling this.\nFAIL_ON_UNKNOWN_PROPERTIES #  Setting FAIL_ON_UNKNOWN_PROPERTIES is useful when working on two systems in paralel. Settings this to false enables clients to send fields to the server that are not yet supported but will be. The alternative would be:\n Server includes those fields as optional fields (to avoid breaking current clients). Server roll-out. Clients update their HTTP clients to include the new fields. Once all-known clients support the new fields, make the same fields mandatory.  By setting this to true, this whole orchestration is not required.\nTODO Sub-Types #  Consider the following example that attempts to model a DSL that supports + and - operations.\nsealed class Expression data class Sum(val a: Int, val b: Int): Expression() data class Sub(val a: Int, val b: Int): Expression() data class Request( @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.EXTERNAL_PROPERTY, property = \u0026#34;type\u0026#34;, visible = true) @JsonSubTypes( JsonSubTypes.Type(value = Sum::class, name = \u0026#34;+\u0026#34;) JsonSubTypes.Type(value = Sub::class, name = \u0026#34;-\u0026#34;) ) val operation: Expression ) In short, this is saying if the JSON contains a field name type with value + it would deserialize to Sum and to Sub if type had value -. I.e., a sum operation between 1 and 2 would require the following JSON payload:\n{ \u0026#34;type\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;operation\u0026#34;: { \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2 } } "});index.add({'id':8,'href':'/knowledge-base/security/jwt/','title':"JWT",'section':"Security",'content':"What it is #  JSON Web Tokens\nWhat it solves #  What it does not solve #  "});index.add({'id':9,'href':'/knowledge-base/system-design/message_driven_architecture/','title':"Message Driven Architecture",'section':"System Design",'content':"Asyncronous and non-blocking. The sender does not actively wait for a response.\nAdvantages:\n Resources are freed immediatly. Reduced contention Messages can be queued for deleivery in case the receiver\u0026rsquo;s is offline. Provides a higher level of reliability.  Disavantages:\n Make transactions more difficult. How to manage long running transactions that span multiple microservices. Holding transactions open for long periods result in slow, brittle systems.  The role of syncronous messags:\n Can you acknowledge the message but process it asyncronously? The need for syncronous messages should be driven by domain requirements rather than technical convenience.  Sagas #  Represent long running transaction. Multiple requests are managed by a Saga.\nIndividual requests are run in sequence or in paralel.\nHow:\n Each request is paired with a compensating action. If any requests fails, compnesation actions are executed for all completed steps. Then the saga is completed with a failure. If compensation actions fails, then it is retried. This requires idempotency.  Timeouts in distributed systems:\n  Eitehr the request failed.\n  Either it was successful but the reply failed.\n  The request is still queued and may success or fail eventually.\nCompensating actions != Rollbacks.\nRollback: implies the transaction has not completed which removes the evidence of the transaction. Compensation: Applied on top of a previously completed action. Evidence of the orignal action remains.\n  Disavantages:\n Coupled to the failures unless we can move regardless of that. Saga are often implemented using ackka actors and represented via Finite State Machine.  Two General Problem #  Illustrate the impossibility of reaching a concensus over an unreliable communication channel.\nDelivery Guarantees #   Exactly Once: Is not possible in the event of a network partition, or lost message. We never guarantee that the message was in-fact sent. Failure requires resending the message which creates potential duplicates. Reuqires storage on both ends: unreliable network (as always); timeouts. At most once - If a failure occur, no retries are done which means no duplications but there may be losses. Requires no storage of messages. At least once - Require a acknoledge and teh sender needs to store state to track whether the messsage was acknowledge. It ahs to be stored in a durable data store.  Exactly once can be simulated using at least once and idempotency.\nAkka: at most once by default. Akka persistence has option to have at least once.\nMessaging Patterns #  Publish Subscribe #  Decoupled. The only coupling is on the message format and possibily the location (e.g., url, exchange on the message broker). Complexity is hard to see as we do not know where the message comes from.\nPoint to point #  Dependencies more clear but coupling is higher. COmplexity is directly observable.\nExamples #  Kafaka, RabbitMQ. Kafka allows point to point and pub/sub and we can even acknowledge once we finish processing.\nAkka: Typically point to point messaging;Persistence Query: Pub/sub Lagom: Point to point communication between services. Messages broker API allow for pub/sub.\n"});index.add({'id':10,'href':'/knowledge-base/messaging-systems/overview/','title':"Messaging Systems Comparison",'section':"Messaging Systems",'content':"Kafka #  Event Streaming, persistent.\nRabbitMQ #  Low latency.\nPulsar #  Made by Apache\nTODO #   Read this comparison: https://www.confluent.io/kafka-vs-pulsar/#:~:text=In%20reality%2C%20Kafka%2C%20RabbitMQ%2C,Pulsar%20sits%20somewhere%20in%20between.  "});index.add({'id':11,'href':'/knowledge-base/system-design/microservices/','title':"Microservices",'section':"System Design",'content':" Referred in\n Service Oriented Architecture   Subset of Service Oriented Architecture where each service is deployed separately:\n Microservices can be physically separated and independently deployed. Each have its own data store. Independent and self governing. Communication is syncronous or asyncronous (e.g., through message brokers). Loose coupling between components (more or less by experience but that is design flaw likely :thinking:). Shorter development and release cycles. Each scale independently (either through physical or virtual machines).  Advantages #   Deployed/Scaled as needed. Increase availability due to reduced single point of failures. Better isolation leading to less couling giving flexibility. Supports multiple platforms and languages. More indepentent Shorter cycles  Mention that cross team coordination become less necessary. That is true but often it still is and requires coordination.\nDisanvantages #   Require multiple complex deployment nad monitoring approaches. Cross service refactors are more challenging. Require supporting old versions. Organization Change  Designing one #   Single responsibility. A change to the internals of one microservice should not necessitate a change to another microservice. Bounded Contexts are a good place to start as they have clear boundaries with its own domain - Question: Can multiple microservices collectively encapsulate a bounded context?  Principles of Isolation #  State #  All access must go thorugh the API and there is no backdoors. Allows internal changes without affecting others.\nSpace #  Should not care where the other services are deployed. Allows microservices to be scaled up or down to meet demands. However, if latency is an issue, they should be in the same region.\nTime #  Should not wait for each other which allows more efficient use of resources. Resources can be freed immediatly, rather than waiting for a request to finish.\nBetween microservices we expect eventual consistency. It improves scalability as total consitency requires central coordination which hindes scalability.\nNOTE: This is discussible. However it may be a implementation details.\nFailure #  Isolate failures and should not cause failure on other systems. I.e., it still is responsive to attend other use-cases.\nIsolation Techniques #  Bulkheading #  Failures are isolated to failure zones. Failures in one service will not propagate to other services. Overall the system remains operation but possibly in a degraded state.\nIn practice it means that that systems that depend on the service that is considered a failure zone, will mark that information or service as unavailable. IMO this is tolerable if the service is non-critical.\nCircuit Breaker #  When a service is under stress we do not want to keep on retrying as it may make things worse.\nWay to avoid overloading a service. They qaurantine a failing service so it can fail fast. Allows the failing service to recover in its time before they fail.\nTypes:\n Closed - Normal Operation Open - Fail fast Half Open - Internally after a timeout will let one request to go through and if it fails, it goes back to Open.  Transitions:\n Closed (normal) -\u0026gt; Trip: Open (Fail Fast) Open (Fail fast) -\u0026gt; Attempt Reset: Half Open Half Open -\u0026gt; Trip: Open (fail Fast) Half Open -\u0026gt; Reset: Closed (Normal)  Message Driven Architecture #   Async and non blocking messages allows decoupling both time and failure. System do not depend on the response from on another. If a request to a service fails, the failure will not propagated. The client service isn\u0026rsquo;t waiting for response. It can continue to operate normally.  Autonomy #  Services can operate independently from each other.\nAutonomous services have enough information to resolve conflicts and repair failures. This means that they do not require other services to be operational all the time. Ideally all the time but in reality for a short time it guarantees some level of autonomy.\nBenefits:\n Stronger scalability and availability. Can be scaled indefinetly. Operate independently.  How:\n Async messages. Maintain enough internal state ofr the microservices to function in isolation. Use eventual consistency. Avoid direct, syncronous dependencies on external services.  API Gateway Services #  Microservices can lead to complexity in the API. How can we manage complex APIs that access many microservices?\nA new microservice that is put between the client and the N-services that are required to fulfill that request. This new microservice is responsible for aggregating the responses moving the responsbility from the client itself. This way, the client only needs to manage failures from the gateway.\nThis effectively creates an additional layer of isolation.\n!! This is specially useful for mobile applicatios where we cannot guarantee that the clients will update their app.\n"});index.add({'id':12,'href':'/knowledge-base/system-design/monolith/','title':"Monolith",'section':"System Design",'content':" Referred in\n Domain Driven Design Service Oriented Architecture   Some notes taken during the lightbend course on Reactive Microservices. Some of these ideas are familiar as they are intuitive.\n Deployed as a single unit. No Clear Isolation. Complex Depedencies -\u0026gt; Hard to understand and modify. Communication using syncronous calls. Hmmm, I disagree and I think that it depends.. E.g., Spring allows services call another with asyncronous methods within the same monolith. I guess that it depends on the spectrum of monolith we are talking about. Big Bang Style Releases Long Cycle Times Careful releases Scalation is done with multiple copies and uses the database as consistency between them.  Advantages:\n Easy Cross Module Refactor Easier to maitain consistency Single Deploy Process Single thing to monitor Simple Scalability Model  Disavantages:\n Limited by the maximum size of a single phyisical machine. Only scales as the database allows. Components are scaled as a group. Deep coupling. Long Dev Cycle. Lack of reliaability given that one failure may impact the whole monolith.  Tearing it up #  Introduce domain boundaries within the application itself (e.g., libraries). Also possible to look for Service Oriented Architecture.\n"});index.add({'id':13,'href':'/knowledge-base/reactive-architecture/patterns/','title':"Patterns",'section':"Reactive Architecture",'content':"CQRS/ES: Command Query Responsibility Segregation and Event Sourcing.\nTwo tools that can be combined.\nUse Cases:\n Auditing (e.g., banking, accounting) High Scalability High Resiliency  There are trade-offs, what are they?\nState Based Persistence #  CQRS #  State Based Persistence. Every time an update is applied to the database it obliterates previous state.\n Can\u0026rsquo;t fix bad state due to previous error. Can\u0026rsquo;t retroactively apply new domain insights (because we do not have the previous states).  This solely tells where we are but not how we got there: These limitations can be worked around with Event Sourcing (ES)\nEvent Sourcing (ES) #  In addition to persisting state, one persists audit logs. This captures the history. It is better to have this in a database as it provides transactionality.\nWary when persisting in the database and in-memory:\n Two potential source of truth if they disagree. Both must be updated in transactionality. A bug in the code may lead to both of them becoming out-of-sync.  Q: What happens if the audit logs gets out-of-sync with the state? A: The audit logs is the source of truth as, as opposition, is not possible to rebuild the audit logs from the current state.\nThis leads to not requiding storing the current state. Event Sourcing captures the intent.\nWhenever we need to obtain the current state we replay the logs until we reach the current state. Attention: We mustn\u0026rsquo;t also replay the side-effects.\nAppend-only is also more efficient in the databases - No deletions or updates.\nEvent Integrity: The logs are the most important thing and should never be rewritten -\u0026gt; immutable events.\nOptimization through snapshots #  What happens if the list of events is too large? Solution: Ocasionally persist a snapshot and we replay the events from that point on (issue: We may receive an event out-of-order, invalidating the snapshot).\nVersioning #  Issue when we have to change the event\u0026rsquo;s schema. This leads to ModelV1, ModelV2, etc. This requires supporting all versions. And requires flexibile formats: JSON, ProtoBuf or AkkA Event Adapters in the lightbend ecosystem that is between the system and the DB translating the V1, V2, VN to the corresponding and unique Domain entity.\nCommand Sourcing #  Similar to command sourcing but persists commands as opposed to events so:\n  Issue command\n  Persist command\n  Run asyncronous the command\n  They should be idempotent as they run multiple times (e.g., failures).\n  Must be validated so that they do not become stuck in the queue forever.\n  Bad: The sender might not be notified if the command fails due to the decouple nature.\n  "});index.add({'id':14,'href':'/knowledge-base/work/random-memories/','title':"Random Memories",'section':"Work",'content':"Curious ideas/sentences and what not from now and then. Some things are pretty obvious but worthwhile remembering (:\n Failure in systems are inevitable. We have to accept and build a system that isolates such failures in a way that becomes unnoticible to the end-user. User does not care whether the software was faulty due to a third-party vender or not. When we build software we have to consider third-party vendors and if we don\u0026rsquo;t properly isolate ourselves from their faulty behavior, users are going to pay for that.     Responsiveness builds user confidence.\n  Domain: Sphere of knowledge that models either a business or an idea.\n  "});index.add({'id':15,'href':'/knowledge-base/documentation/readme/','title':"readme",'section':"Documentation",'content':"Several examples #    https://github.com/matiassingers/awesome-readme\nKey take-ways of some:\n Logo top TOC (horizontally) Demo How to use LICENCE  Like minimalistic versions as they require less maintenance (hmmm :thinking-face:)\n  "});index.add({'id':16,'href':'/knowledge-base/system-design/service_oriented_architecture/','title':"Service Oriented Architecture",'section':"System Design",'content':" Referred in\n Monolith Microservices   As opposed to Monolith, services do not share a database and all access must be done through a API exposed by the service. They may be in the same process (Monolith) or may be separated (Microservices). This reduces coupling.\nE.g.:\n Orders -\u0026gt; RDBMS Customers -\u0026gt; No SQL Reservations -\u0026gt; Web Service Menu -\u0026gt; RDBMS  "});index.add({'id':17,'href':'/knowledge-base/data-processing/states-of-data/','title':"States of Data",'section':"Data Processing",'content':"States of data:\n At Rest: Data that is not consumed at the time is injested. It is stored and then consumed later in a batch process. In Transit: Data that is travelling between point A and point B. In Use: Data that is opened for treatment  Encountered several concerns regarding how such data must be handled. Follows a link to be reviewed later:three-states-of-data\n"});index.add({'id':18,'href':'/knowledge-base/work/way-of-work/','title':"Way of work",'section':"Work",'content':"It\u0026rsquo;s not about being right nor prove others wrong #   Corollary 1: if it\u0026rsquo;s wrong but it works, then it\u0026rsquo;s not wrong. Corollary 2: if you\u0026rsquo;re right but it doesn\u0026rsquo;t change the outcome, then it doesn\u0026rsquo;t matter. Corollary 3: if you\u0026rsquo;re right, but it doesn\u0026rsquo;t work, then you\u0026rsquo;re wrong. Corollary 4: if you prove someone else wrong, but their answer works and yours doesn\u0026rsquo;t, then they\u0026rsquo;re right and you\u0026rsquo;re wrong. Corollary 5: if you prove someone\u0026rsquo;s solution to be wrong even though it does provide value, then you have not yet provided any value until you propose something better.  "});index.add({'id':19,'href':'/knowledge-base/blog-ideas/using_psql_as_job_queue/','title':"Using PSQL as job queue",'section':"Blog Ideas",'content':"Use-case: Process event queue stored in PSQL:\n Dequeue size item. Process each item.  As expected, resiliency and concurrent systems leads to devious details where the resolution largely depends on the use-case:\n Multiple nodes accessing the same queue. What happens if the node crashes while it processes the item. Will the event loss?  Consider the following table:\nDROP TABLE IF EXISTS \u0026#34;queue\u0026#34;; CREATE TABLE \u0026#34;queue\u0026#34; ( \u0026#34;id\u0026#34; SERIAL, \u0026#34;dequeued_at\u0026#34; TIMESTAMP NULL, -- remaining fields relevant for the use-case. For the outbox pattern, one would be storing the event in JSON format, the event id and the event\u0026#39;s timestamp. ); This table represent a queue in the database. In order to fetch size elements from the queue:\nUPDATE event_queue SET dequeued_at = current_timestamp WHERE id IN ( SELECT id FROM queue WHERE dequeued_at IS NULL OR current_timestamp \u0026gt;= (dequeued_at + interval \u0026#39;1 second\u0026#39; second * :seconds) ORDER BY event_timestamp ASC LIMIT :size FOR UPDATE SKIP LOCKED ) RETURNING *  One can simplify this to solely fetch one element at at a time but this reduces the connections done in the DB. It depends on the use-case.  Breaking down:\n UPDATE event_queue SET dequeued_at = current_timestamp + ~FOR UPDATE SKIP LOCKED - Guarantees that multiple nodes reading N elements from the queue will have disjoint sets. WHERE dequeued_at IS NULL - Condition to check if the item was dequeued. current_timestamp \u0026gt;= (dequeued_at + interval '1 second' second * :seconds) - Guarantees that multiple nodes will not process the same elements.  Alternatives:\n Just delete the entity, however it incurs the risk if processing the element fails leading to the loss.  References:\n   "});index.add({'id':20,'href':'/knowledge-base/uncategorized/akka/','title':"Akka",'section':"Uncategorized",'content':"Akka Distributed Data #  CRDTs in distributed data are stored in memory. Can be copied to disk to speed up recovery if a replica fails.\nBest used for small data sets with infrequent updates that require high availability.\nLimitations CRDT: Do not work with every data type that require a merge function. Some data types are too complex to merge and require the use of tombstone:\n A marker that shows something was deleted. Can result in data types that only get larger and never smaller. Aka CRDT Garbage  "});index.add({'id':21,'href':'/knowledge-base/uncategorized/lightbend-academy/','title':"Lightbend Academy",'section':"Uncategorized",'content':" Referred in\n Domain Driven Design   Some notes regarding Lighbend academy at https://academy.lightbend.com/. Taking this opportunity as it is free during this summer.\nHope to learn more about Reactive + Akka + Actors + Streams.\nHmmm\u0026hellip; is Data Engineering something I would like to work with? :thinking:\nTODO TENHO QUE FAER ISTO #  DONE CENAS #  [X] DONE #   CENAS AQUI\n case class Cenas(val a: Int) case class Outras(val b: Int) sealed trait Maybe[+T] final case object Empty extends Maybe[Nothing] final case class Just[T](t: T) extends Maybe[T] println(2) val a = Just(2) println(a) Glossary #  **\nCenas #  Cenas #     Cenas\n   Cenas\n   Cenas\n Data at Rest: Data that is not consumed at the time is injested. It is stored and then consumed later in a batch process.        Introduction to Reactive Systems #  Context: Increasing complexity which requires many nodes (2-3 on simpler) and far more nodes on more complex systems. And the amount of data that is handled today is far larger that it was before, in order to petabytes and is no longer rest, i.e., is actively changing making very hard to catch up.\nGoal: Provide an experience that is responsive under all conditions:\n Scale from 10 users to million of users. Consume solely the resources required to support the current work-load (IMO this does not say much, maybe they are referring to the lack of batch jobs that periodically run?) It scales horizontally across several nodes Consistent level of quality and responsiveness  Well.. they provide some explanations regarding avoiding downtime, I am curious which use-cases where this architecture solves as they are use-cases where this can be tricky.\nReactor Principles #   Most important: Responsive - Always respond in a timely manner. Leads to have to be resiliency even when failures occur. Elastic to keep responsive specially when the system load changes - goes both ways as keeping lots of resources is expensive specially when unjustified. Foundation on Message Driven (or event driven in reactive manifesto) - Async and non-blocking message.  On resiliency: #  Achieved through:\n Replication Isolation Containment Delegation  Isolation on single components. Recovery is delegated to an external component. Hmmm, kinda reminds me k8s when it detects Pods as not ready and forwards traffic to the remaining pods.\nOn Elasticicity #  Responsivess regardless of the load. Zero contention and no central bottlenecks - Seems like to be good be true despite possible. Well.. isn\u0026rsquo;t what we always want regardless of the architecture? Predictive Auto-Scaling techniques. Responsiveness during peaks while scaling down assures cost effectivness without losing responsiviness.\nOn MEssage Driven #  All previous principles are supported by this. Loose coupling, isolation and location transparency - I kinda disagree with loose coupling, as the systems still will still depend on 3rd party behavior regardless of the communication medium. Resources are only consumed while active. Idea is that we we stop using resources while waiting for an system to respond, we can do something else while the response haven\u0026rsquo;t arrived (async)\nReactive Principles Example - git #  Git is a good example regarding reactive principles:\n Asyncronous and non-blocking as the work is submitted through PR and I can keep on working locally with no interruptions. Message based as it is basically \u0026ldquo;please review this\u0026rdquo;. SeeActor Model. Resiliency as each user has basically a copy of the whole repository locally. The local machine is isolated from the remote. Elastic has we can have multiple copies and does not cause problemas having that repository sync on that many machines. Responsive.  Reactive Programming vs Reactive Systems #  They are not the same.\nReactive systems apply the reactive principles on a architectural level.\nReactive Programming can be (and often is) used to build reactive systems but that does not mean that it is a reactive system.\nIn order to have a reactive architecture, it means that the reactive systems needs to be separated thorugh asyncronous boundaries.\nTODO https://www.lightbend.com/white-papers-and-reports/reactive-programming-versus-reactive-systems #  Domain Driven Design #  Goal: Software implementation that is based on an evolving model that is understood by the domain experts.\nDomain: Sphere knowledge. Referes to busuiness or idea we are trying to model.\nTHe software is the implementation of such domain that experts are able to understand.\nGoal: Build a model that domain expderts understand. One that we show them without they understanding the Software.\nLEads to a way to communicate with them.\nIt is important to mention that the model is not hte software. Model represents the understanding of hte domain. The softewrae is solely the implementation of hte model. It can be implemented on diagrams which is not software but an implementation nonetheless.\nBut the software should be implemented in a way that reflecfts the model in a way that 1:1 parity between the model and the implementation.\nThis requires a common language that both parties. understand leading to:\n Ubiquitous Language: Common language that enables communication between the domain experts and the developers. Terminologuy in there comes from the domain experts. Software termms should be avoided. However sometimes we have to introduce soem terms to the language and such terms should go through the domain experts as well as they may have already a work for that.  Decomposing #  Business domains are typically large and complicated. With many ideas, actions and rules taht interact in complex ways.\nStrategy: Take the large domain and seperate onto sub domains by grouping related ideas, actions and rules - Maybe use-cases?\nHowever it is normal having conceps that span multiple sub domains however it is important to avoid abstract already as there may be slight changes. For example, a customer in the context of an online order is different from a customer in the context of in-store purchase. Therefore, there should be modeled as different entities.\nBounded Context: Ubiquotious Language and model for a sub-domain. The meaning of a concept by change from one bounded context to another.\nMicroservices are built around bounded contexts.\nHow to determine those boundaries? Some guidelines:\n IMO Use-cases\u0026hellip; Consider human culture and interactions, i.e., how different groups of people interact with a given entity. Look for changes in the ubiquitous language. Variations suggest a new context. Look for variations where the informatio become relevant/irrelevant.  Strongly separated bounded contexts reuslt in smooth workflows.\nIf it awkwards it may be due to a misunderstanding of the domain.\nEvent First Domain Driven Design #  Look at the activities (i.e. use-cases?) and start grouping such activities.\nTODO Event Storming - Check what it is #  Reactive Barbecue #  Does inventory managament to menu pricing to deliveries and online orders and reservations.\nOther #  TODO There is a thing called Reactive Manifesto #  https://github.com/reactivemanifesto/reactivemanifesto\n"});index.add({'id':22,'href':'/knowledge-base/uncategorized/org_protocol/','title':"Org-Protocol",'section':"Uncategorized",'content':"Useful guide: https://github.com/xuchunyang/setup-org-protocol-on-mac\n"});index.add({'id':23,'href':'/knowledge-base/uncategorized/relevant-xkcds/','title':"Relevant xkcds",'section':"Uncategorized",'content':"On Standards #  https://xkcd.com/927/\n"});})();