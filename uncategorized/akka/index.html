<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Akka #  Toolkit and runtime for building highly concurrent, distributed and fault tolerant message-driven application in the JVM. It can be used to build Reactive Systems.
Proposes unified programming model for:
 Simpler concurrency: single threaded ilusion as each actor processes a messsage at a time). Simpler distribution: is distributed by default). Simpler fualt tolerancy: Decouples communication from failure handling.  Akka Cluster #  Allows actors to communicate across the network, greatly simplifying the process."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Akka"><meta property="og:description" content="Akka #  Toolkit and runtime for building highly concurrent, distributed and fault tolerant message-driven application in the JVM. It can be used to build Reactive Systems.
Proposes unified programming model for:
 Simpler concurrency: single threaded ilusion as each actor processes a messsage at a time). Simpler distribution: is distributed by default). Simpler fualt tolerancy: Decouples communication from failure handling.  Akka Cluster #  Allows actors to communicate across the network, greatly simplifying the process."><meta property="og:type" content="article"><meta property="og:url" content="https://bphenriques.github.io/knowledge-base/uncategorized/akka/"><title>Akka | Bruno Henriques</title><link rel=manifest href=https://bphenriques.github.io/knowledge-base/manifest.json><link rel=icon href=https://bphenriques.github.io/knowledge-base/favicon.png type=image/x-icon><link rel=stylesheet href=https://bphenriques.github.io/knowledge-base/book.min.1251f5eefcf487ae0df4b5a44283e1e26687a9e19d3af75df0afe44c4689ad10.css integrity="sha256-ElH17vz0h64N9LWkQoPh4maHqeGdOvdd8K/kTEaJrRA="><script defer src=https://bphenriques.github.io/knowledge-base/en.search.min.acc26235e16b46be40607cec3c01a00581c906aa876207f02020c7e6da82708b.js integrity="sha256-rMJiNeFrRr5AYHzsPAGgBYHJBqqHYgfwICDH5tqCcIs="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=https://bphenriques.github.io/knowledge-base/><span>Bruno Henriques</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Concurrency</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/concurrency/actor-model/>Actor Model</a></li><li><a href=https://bphenriques.github.io/knowledge-base/concurrency/amdah_s_law/>Amdah's Law</a></li><li><a href=https://bphenriques.github.io/knowledge-base/concurrency/gunther_s_universal_scalability_law/>Gunther's Universal Scalability Law</a></li></ul></li><li class=book-section-flat><span>Data Processing</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/data-processing/apache-spark/>Apache Spark</a></li><li><a href=https://bphenriques.github.io/knowledge-base/data-processing/states-of-data/>States of Data</a></li></ul></li><li class=book-section-flat><span>Databases</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/databases/overview/>Overview</a></li><li><a href=https://bphenriques.github.io/knowledge-base/databases/databases_sharding-or-partitioning/>Sharding or Partitioning</a></li></ul></li><li class=book-section-flat><span>Documentation</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/documentation/readme/>Readme</a></li></ul></li><li class=book-section-flat><span>Editors</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/editors/emacs/>Emacs</a></li></ul></li><li class=book-section-flat><span>Learning</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/learning/coursera/>Coursera</a></li><li><a href=https://bphenriques.github.io/knowledge-base/learning/hands_on_scala_programming/>Hands-on Scala Programming</a></li><li><a href=https://bphenriques.github.io/knowledge-base/learning/technical_writing/>Technical Writing</a></li></ul></li><li class=book-section-flat><span>Messaging Systems</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/messaging-systems/messaging-systems-overview/>Messaging Systems Comparison</a></li></ul></li><li class=book-section-flat><span>Monitoring</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/monitoring/bug-management/>Bug Management</a></li></ul></li><li class=book-section-flat><span>Protocols</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/protocols/gossip_protocol/>Gossip Protocol</a></li><li><a href=https://bphenriques.github.io/knowledge-base/protocols/heartbeat/>Heartbeat</a></li></ul></li><li class=book-section-flat><span>Resources</span><ul></ul></li><li class=book-section-flat><span>Security</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/security/jwt/>JWT</a></li></ul></li><li class=book-section-flat><span>System Design</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/system-design/command_query_responsibility_segregation/>Command Query Responsibility Segregation (CQRS)</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/command_sourcing/>Command Sourcing</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/consistency_and_availability/>Consistency And Availability</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/domain_driven_design/>Domain Driven Design</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/event_sourcing/>Event Sourcing</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/message_driven_architecture/>Message Driven Architecture</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/microservices/>Microservices</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/monolith/>Monolith</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/reactive_systems/>Reactive Systems</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/service_oriented_architecture_soa/>Service Oriented Architecture (SOA)</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/system-design_sli-slo/>SLI/SLO</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/system-design_stateless/>Stateless</a></li><li><a href=https://bphenriques.github.io/knowledge-base/system-design/articles/>System Design Articles</a></li></ul></li><li class=book-section-flat><span>Work</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/work/curriculum/>Curriculum</a></li><li><a href=https://bphenriques.github.io/knowledge-base/work/random-memories/>Random Memories</a></li><li><a href=https://bphenriques.github.io/knowledge-base/work/thinking_tools/>Thinking Tools</a></li><li><a href=https://bphenriques.github.io/knowledge-base/work/way-of-work/>Way of work</a></li></ul></li><li class=book-section-flat><span>Snippets</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/snippets/emacs/>Emacs</a></li><li><a href=https://bphenriques.github.io/knowledge-base/snippets/jackson/>Jackson</a></li></ul></li><li class=book-section-flat><span>Blog Ideas</span><ul></ul></li><li class=book-section-flat><span>Uncategorized</span><ul><li><a href=https://bphenriques.github.io/knowledge-base/uncategorized/akka/ class=active>Akka</a></li><li><a href=https://bphenriques.github.io/knowledge-base/uncategorized/dotfiles/>dotfiles</a></li><li><a href=https://bphenriques.github.io/knowledge-base/uncategorized/nix/>Nix</a></li><li><a href=https://bphenriques.github.io/knowledge-base/uncategorized/relevant-xkcds/>Relevant xkcds</a></li><li><a href=https://bphenriques.github.io/knowledge-base/uncategorized/web-stack-enties/>Stack Web Notes</a></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://bphenriques.github.io/knowledge-base/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Akka</strong>
<label for=toc-control><img src=https://bphenriques.github.io/knowledge-base/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#akka>Akka</a></li><li><a href=#akka-cluster>Akka Cluster</a></li><li><a href=#akka-cluster-aware-routers>Akka Cluster Aware Routers</a></li><li><a href=#akka-cluster-sharding>Akka Cluster Sharding</a></li><li><a href=#akka-distributed-data>Akka Distributed Data</a><ul><li><a href=#other>Other</a></li></ul></li><li><a href=#akka-address>Akka Address</a></li><li><a href=#joining-a-cluster>Joining a Cluster</a></li><li><a href=#akka-cluster-management>Akka Cluster Management</a><ul><li><a href=#akka-discovery>Akka Discovery</a></li><li><a href=#akka-cluster-bootstrap>Akka Cluster Bootstrap</a></li><li><a href=#health-check-endpoints>Health Check Endpoints</a></li></ul></li><li><a href=#communication>Communication</a></li><li><a href=#network-partitions>Network Partitions</a></li><li><a href=#split-brain>Split Brain</a><ul><li><a href=#when-using-sharding-or-singleton-for-data-consistency>When using sharding or singleton for data consistency</a></li></ul></li><li><a href=#lighbend-split-brain-resolver>Lighbend Split Brain Resolver</a><ul><li><a href=#static-quorum>Static Quorum</a></li><li><a href=#keep-majority>Keep Majority</a></li><li><a href=#keep-oldest>Keep Oldest</a></li><li><a href=#keep-referee>Keep Referee</a></li><li><a href=#down-allows>Down Allows</a></li><li><a href=#lease-majority>Lease Majority</a></li><li><a href=#some-edge-cases>Some Edge Cases</a></li></ul></li><li><a href=#orphaned-node>Orphaned Node</a></li><li><a href=#cluster-singleton><span class="org-todo todo TODO">TODO</span> Cluster Singleton</a></li><li><a href=#akka-cluster-sharding>Akka Cluster Sharding</a><ul><li><a href=#entities>Entities</a></li><li><a href=#shard>Shard</a></li><li><a href=#shard-region>Shard Region</a></li><li><a href=#shard-coordinator>Shard Coordinator</a></li></ul></li><li><a href=#handling-messages-asyncronously>Handling Messages Asyncronously</a></li><li><a href=#passivation>Passivation</a></li><li><a href=#rebalancing>Rebalancing</a><ul><li><a href=#remember-entities>Remember Entities</a></li></ul></li><li><a href=#semantics>Semantics</a></li><li><a href=#akka-actor-lifecycle>Akka Actor Lifecycle</a><ul><li><a href=#monitor>Monitor</a></li></ul></li><li><a href=#failure-handling>Failure Handling</a><ul><li><a href=#full-lifecycle>Full Lifecycle</a></li></ul></li><li><a href=#ask-vs-tell>Ask vs Tell</a></li><li><a href=#router><span class="org-todo todo TODO">TODO</span> Router</a></li><li><a href=#akka-streams>Akka Streams</a><ul><li><a href=#how>How</a></li><li><a href=#backpressure>Backpressure</a></li></ul></li></ul></nav></aside></header><article class=markdown><h2 id=akka>Akka
<a class=anchor href=#akka>#</a></h2><p>Toolkit and runtime for building highly concurrent, distributed and fault tolerant message-driven application in the JVM. It can be used to build <a href=https://bphenriques.github.io/knowledge-base/system-design/reactive_systems/>Reactive Systems.</a></p><p>Proposes unified programming model for:</p><ul><li>Simpler concurrency: single threaded ilusion as each actor processes a messsage at a time).</li><li>Simpler distribution: is distributed by default).</li><li>Simpler fualt tolerancy: Decouples communication from failure handling.</li></ul><h2 id=akka-cluster>Akka Cluster
<a class=anchor href=#akka-cluster>#</a></h2><p>Allows actors to communicate across the network, greatly simplifying the process. All members must share the same.</p><ul><li>What is the purpose of the name? :thinking:</li></ul><h2 id=akka-cluster-aware-routers>Akka Cluster Aware Routers
<a class=anchor href=#akka-cluster-aware-routers>#</a></h2><p>Context: High workload.</p><p>Scalling vertically has limits (including expenses). Introducing Akka Cluster Aware Routers, that allows work to be distributed across cluster. A large task is broken on smaller tasks that is routed to an instance of our application. This means that we may scale horizontally.</p><h2 id=akka-cluster-sharding>Akka Cluster Sharding
<a class=anchor href=#akka-cluster-sharding>#</a></h2><p>Context: Database becomes the bottleneck.</p><p>Many applications leverage the database, specially to create consistency however this leads to contention (see <a href=https://bphenriques.github.io/knowledge-base/concurrency/amdah_s_law/>Amdah&rsquo;s Law</a>). As the application scales, the database cannot keep up.</p><p>Akka distributes actors across the cluster. And each actor maintains state for a specific database identifier. This eliminates database&rsquo;s reads for a specific database identifier. The actor may reply directly. The actor model guarantees that the state and the database are always consistent (how exactly?).</p><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201007_221440screenshot.png></figure><h2 id=akka-distributed-data>Akka Distributed Data
<a class=anchor href=#akka-distributed-data>#</a></h2><p>Context: Shared State/Data problem</p><p>Either in the database, or sometimes offload to a dedicated cache service like Memcached or Redis, essentially moving the bottleneck. Additionally, it leads to additional infrastructure burden.</p><p>Akka Distributed Data provides local, replicated, in-memory data storage.</p><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201007_222154screenshot.png></figure><p>The data is asyncronously replicated to another nodes, ensuring all nodes have access to the data. This is made with low latency and ensures fast updates across the cluster (Why given that each nodes is responsible for a specific database identifier? What happens if a node goes down?).</p><h3 id=other>Other
<a class=anchor href=#other>#</a></h3><p>CRDTs in distributed data are stored in memory. Can be copied to disk to speed up recovery if a replica fails.</p><p>Best used for small data sets with infrequent updates that require high availability.</p><ul><li>A marker that shows something was deleted.</li><li>Can result in data types that only get larger and never smaller.</li><li>Aka CRDT Garbage</li></ul><p>Limitations CRDT: Do not work with every data type that require a merge function. Some data types are too complex to merge and require the use of <em>tombstone</em>:</p><h2 id=akka-address>Akka Address
<a class=anchor href=#akka-address>#</a></h2><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201007_224144screenshot.png></figure><p>May be local or remote in the form:
<code>akka://&lt;ActorSystem>@&lt;HostName>:&lt;Post>/&lt;ActorPath></code></p><p>Several protocols are available and depend on the use-case:</p><ul><li><code>aeron-udp</code>: High throughput and low latency (and probabilly lacks delivery guarantees?)</li><li><code>tcp</code>: Good thorughout and latency but lower.</li><li><code>tls-tcp</code>: When encryption is required.</li></ul><h2 id=joining-a-cluster>Joining a Cluster
<a class=anchor href=#joining-a-cluster>#</a></h2><p>Requires &ldquo;Seed Nodes&rdquo;, i.e., contact nodes. Any node is eligible. Best practice is to use &ldquo;Akka Cluster Bootstrap&rdquo; to avoid static configuration.</p><p>Must be enabled! And it does not bring any advantage until we set the application to leverage this:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=color:#66d9ef>val</span> loyaltyActorSupervisor <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>ClusterSharding</span><span style=color:#f92672>(</span>system<span style=color:#f92672>).</span>start<span style=color:#f92672>(</span>
   <span style=color:#e6db74>&#34;shared-region-name&#34;</span><span style=color:#f92672>,</span>
    <span style=color:#a6e22e>MyActorActor</span><span style=color:#f92672>.</span>props<span style=color:#f92672>(</span>someProp<span style=color:#f92672>),</span>
    <span style=color:#a6e22e>ClusterShardingSettings</span><span style=color:#f92672>(</span>system<span style=color:#f92672>),</span>
    <span style=color:#a6e22e>MyActorSupervisor</span><span style=color:#f92672>.</span>idExtractor<span style=color:#f92672>,</span>
    <span style=color:#a6e22e>MyActorSupervisor</span><span style=color:#f92672>.</span>shardIdExtractor
  <span style=color:#f92672>)</span>
</code></pre></div><h2 id=akka-cluster-management>Akka Cluster Management
<a class=anchor href=#akka-cluster-management>#</a></h2><p>Set of tools served through a HTTP Api to manage the cluster. Must start after the actor system.</p><p>Must be enabled!</p><h3 id=akka-discovery>Akka Discovery
<a class=anchor href=#akka-discovery>#</a></h3><p>Service to locate and discover services.</p><h3 id=akka-cluster-bootstrap>Akka Cluster Bootstrap
<a class=anchor href=#akka-cluster-bootstrap>#</a></h3><p>Automated seed node discovery using Akka Discovery.</p><h3 id=health-check-endpoints>Health Check Endpoints
<a class=anchor href=#health-check-endpoints>#</a></h3><p>Useful when integrating with orchestrating platforms (e.g., K8S).</p><h2 id=communication>Communication
<a class=anchor href=#communication>#</a></h2><p>It is done by using <a href=https://bphenriques.github.io/knowledge-base/protocols/gossip_protocol/>Gossip Protocol</a>.</p><h2 id=network-partitions>Network Partitions
<a class=anchor href=#network-partitions>#</a></h2><p>This issue cannot be recovered by simply rebooting the affected node. In order to fix this:</p><ol><li>Decide which partitions needs to be cleaned up - How?</li><li>Shutdown the members</li><li>Inform the cluster that those members are down - <code>PUT -F operation=down /cluster/members/&lt;member address></code>.</li><li>Create new members to replace the old.</li></ol><p>Step 2. is important otherwise it continues to operate unware that it has been removed from the cluster which can lead to multiple copies of the same shard.</p><h2 id=split-brain>Split Brain
<a class=anchor href=#split-brain>#</a></h2><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201008_232738screenshot.png></figure><p>Occurs when single cluster splits into two or more distinctive clusters. It normally does not occur unless poor management (not stopping processes that are <em>Down</em>) or configuration (there are strategies to solve this automatically). Can be caused by improper <em>Downing</em> a member leading to the node creating another cluster as the process was not terminated.</p><p>It may also occur with a network partition. If this extend, the <em>Unreachable Nodes</em> will be marked as downed but will not be terminated.</p><p>Simpler solutions may be solved automatically through orchestration platforms that automatically stop the process. More complicated split brains may be solved using <em>Lightbend Split Brain Resolver</em>.</p><h3 id=when-using-sharding-or-singleton-for-data-consistency>When using sharding or singleton for data consistency
<a class=anchor href=#when-using-sharding-or-singleton-for-data-consistency>#</a></h3><p>Each cluster can have a copy of the actor leading to a inconsistency and data corruption specially if both shards have access to the database.</p><h2 id=lighbend-split-brain-resolver>Lighbend Split Brain Resolver
<a class=anchor href=#lighbend-split-brain-resolver>#</a></h2><p>Set of customizable strategies for terminating members in order to avoid Split Brain scenarios. Terminating members allow orchestration platforms to take over and heal the problem.</p><h3 id=static-quorum>Static Quorum
<a class=anchor href=#static-quorum>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201008_235124screenshot.png></figure><p>Fixed sized quorom of node. All nodes will evaluate their situation and <em>Down</em> unreachable. If quorum is set then a smaller cluster will prevail, otherwise the nodes will shutdown themselves. The quorum value must at least <code>n/2 + 1</code>.</p><h3 id=keep-majority>Keep Majority
<a class=anchor href=#keep-majority>#</a></h3><p>Similar to previous but dynamically tracks the size of the cluster.</p><h3 id=keep-oldest>Keep Oldest
<a class=anchor href=#keep-oldest>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201008_235425screenshot.png></figure><p>Monitors the oldest node in the cluster. Members that are not communicating with that node will be marked as down and the nodes will terminate themselves. If the oldest node has crashed so will the cluster but is configurable in a way, that in that case only the oldest will be <em>Downed</em>.</p><h3 id=keep-referee>Keep Referee
<a class=anchor href=#keep-referee>#</a></h3><p>Similar to the other one but designate a specific node as <em>referee</em> (based on its address). As far as I can see, it is not configurable to avoid crashing the cluster if the <em>referee</em> is down.</p><h3 id=down-allows>Down Allows
<a class=anchor href=#down-allows>#</a></h3><p>All nodes terminate themselves relying on good orchestration tools to reduce downtime - Me not like this one.</p><h3 id=lease-majority>Lease Majority
<a class=anchor href=#lease-majority>#</a></h3><p>Reserved for Kubernetes deployments.</p><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201008_235848screenshot.png></figure><p>It uses a distributed <em>lock</em> (lock) to make it&rsquo;s decision. Each partition will attempt to obtain it the loser terminates and the winnner remains.</p><p>There is a bit of nice hack (IMO but can&rsquo;t understand exactly how this is achieved) which is that the side that is theoretically smaller will delay the attempt to obtain the lock so that the majority wins.</p><h3 id=some-edge-cases>Some Edge Cases
<a class=anchor href=#some-edge-cases>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201009_000309screenshot.png></figure><ul><li>Indirect connected Edges (for some reason is connected to only one member).</li><li>Unstable nodes (keeps on disconnecting from some nodes).</li></ul><p>These edge-caes are automatically handled.</p><h2 id=orphaned-node>Orphaned Node
<a class=anchor href=#orphaned-node>#</a></h2><p>Is down but not terminated.</p><h2 id=cluster-singleton><span class="org-todo todo TODO">TODO</span> Cluster Singleton
<a class=anchor href=#cluster-singleton>#</a></h2><h2 id=akka-cluster-sharding>Akka Cluster Sharding
<a class=anchor href=#akka-cluster-sharding>#</a></h2><p>Distribute actors across a cluster.</p><h3 id=entities>Entities
<a class=anchor href=#entities>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201010_164050screenshot.png></figure><p>Unique within the cluster. Acts as a single source of truth leading to <em>Strong Consistency</em>.</p><p>Entities agre grouped into Shards.</p><p>Typically they correspond to the domain concept that the entity is modelling and the identifier is usually the aggregate root&rsquo;s identifier (e.g. <em>UserId</em>).</p><p>For this purpose we can use <code>Extractor</code> that is often modeled using a Envelope (which is not mandatory if the mssage contains the identifier):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=color:#66d9ef>case</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Envelope</span><span style=color:#f92672>(</span>entityId<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>,</span> message<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Any</span><span style=color:#f92672>)</span>

<span style=color:#66d9ef>val</span> idExtractor<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>ExtractEntityId</span> <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
   <span style=color:#66d9ef>case</span> <span style=color:#a6e22e>Envelope</span><span style=color:#f92672>(</span>id<span style=color:#f92672>,</span> msg<span style=color:#f92672>)</span> <span style=color:#66d9ef>=&gt;</span> <span style=color:#f92672>(</span>id<span style=color:#f92672>,</span> msg<span style=color:#f92672>)</span>
<span style=color:#f92672>}</span>
</code></pre></div><h3 id=shard>Shard
<a class=anchor href=#shard>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201010_165840screenshot.png></figure><p>Holds entities. The distribution depends on a function which procuces the <em>Shard Id</em> (usually based on the <em>Entity Id)</em>. Mapping entities to <em>Shard Id</em> dictates how to control the distribution of the entities across the cluster. Improper distribution may lead to hotspots in the cluster (unbalance).</p><p>Rule of thumb: ~10 shards per node. Too many shards have a cost to find them. And too short reduces capability to distribute the nodes on the cluster (e.g., 2 shard across 3 nodes).</p><p>Example of unbalanced ids:</p><ul><li>Names of people: Creates hotspots for common names.</li><li>Dates: Hotspots for recent dates.</li><li>Auto-incrementing ids: Hotspots for recent ids.</li></ul><p>Usually the best is <code>Math.abs(hashCode % number_shards)</code>.</p><h3 id=shard-region>Shard Region
<a class=anchor href=#shard-region>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201010_170205screenshot.png></figure><p>Holds Shards. For a type of entity, there is usually one Shard Region per JVM.</p><h3 id=shard-coordinator>Shard Coordinator
<a class=anchor href=#shard-coordinator>#</a></h3><p>Runs as a Akka Cluster Singleton. It is responsible to route the messages addressed to a specific entity. It provides the location of the shard which can then be used to acccess the entity.</p><p>Backed by Akka Distributed Data or Akka Persistence.</p><h2 id=handling-messages-asyncronously>Handling Messages Asyncronously
<a class=anchor href=#handling-messages-asyncronously>#</a></h2><p>Blocking threads inside the actors creates contention therefore the handling of the messages must happen in a async fashion, including any DB writes and DB reads when starting the actor. For example, using interfaces such as <code>Future[T]</code>. However this may lead to concurrency within the actor itself removing the ilusion of a single thread. This means that messages must be <em>stash</em> until other operations complete.</p><p>In essence the actor has 3 states:</p><ul><li>Loading - Load the state from the DB.</li><li>Running - Regular behavior.</li><li>Waiting.</li></ul><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201011_002542screenshot.png></figure><p><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201011_002523screenshot.png alt>
Question: If DB fails, then it is recommended to throw the exception leading to a restart of the Actor that in turn will re-read the state from the DB. So:</p><ul><li>It is explained that the stash is not lost, how?</li><li>What happens if there is a persistent issue in the DB? Will there be a loop?</li></ul><h2 id=passivation>Passivation
<a class=anchor href=#passivation>#</a></h2><p>This fenomenon can be observer through small dips in the throughput. This happens as the Actors attempts to manage the number of actors in-memory as keep all of them is unreasonable. E.g., idle actors.</p><p>Each actor tracks the time it processed a message. If it hadn&rsquo;t processed a message within a configured time period, it will <em>Passivate</em>, leading to the removal of the actor in-memory.</p><p>The period must be tune-up, too long may lead to OOM and too short may lead to constant reads from the DB. Best practise is to determine and then tune up by watching the memory usage.</p><p>It can also be done manually by sending a <em>Passivate</em> message to the parent.</p><h2 id=rebalancing>Rebalancing
<a class=anchor href=#rebalancing>#</a></h2><p>Occurs whenever the size of the cluster changes. The Shard coordinator will initiate the rebalancing process by distributing the shards across the all available nodes in order to keep an even distribution of entities.</p><p>This can only occur in a healthy cluster. Therefore any unreachable nodes must be removed (and terminated <strong>before</strong>) either manually through <em>Akka Management</em> or using the <em>Lightbend Split Brain Resolver</em>.</p><p>Steps:</p><ol><li>Coordinator informs Regions that a rebalance has started.</li><li>Messages to an entity on a moving shard are buffered.</li><li>Oce shared was rebalanced, the queued messages are sent</li></ol><h3 id=remember-entities>Remember Entities
<a class=anchor href=#remember-entities>#</a></h3><p>The entities are not autoamtically restarted until they are requested again. It can be configured otherwise by enabling <code>remember-entities</code>. When a node restarts/rebalances, it will restore those entities. This works by informing every member every time each entity starts or stops (using Akka distributed data) and stored in a durable storage in the disk (it can be recovered even after full cluster restart) - Hmm, but what if this is running in K8S where the disks are ephemeral? :thinking:</p><p>Warning!</p><ul><li>Enabling this disables <strong>automatic</strong> passivation.</li><li>It is not cheap as every node will track every running entity and adds overhead when starting/stopping entities.</li></ul><p>Best practice is to limit when we have a limited number of active entities. Most of times is not really needed as entities will be removed automatically through <em>Passivation</em> brought back when needed. However some use-cases:</p><ul><li>When the entity has a scheduled process that may not have completed.</li><li>When the time to restart an entity on demand could cause the system to backup (long startup times).</li><li>When the resource savings of passivating the Entities are insignificant.</li></ul><p>With this feature, the node&rsquo;s <code>ExtractShardIf</code> function must handle <code>ShardRegion.StartEntity(entityId)</code>.</p><h2 id=semantics>Semantics
<a class=anchor href=#semantics>#</a></h2><p>Message delivery in Akka is is best effort (at-most-once, the default). Not sure if I like this :thinking:</p><h2 id=akka-actor-lifecycle>Akka Actor Lifecycle
<a class=anchor href=#akka-actor-lifecycle>#</a></h2><p>Can be stopped by himself or by others.</p><p>Lifecycle (without faults):</p><pre><code class=language-nil data-lang=nil>hook:preStart() -&gt; started -[stop]-&gt; stopped -&gt; hook:postStop() -&gt; terminated
</code></pre><p>The actor is created assyncronously and available right away through the <code>ActorRef</code>.</p><p>Stopping an actor will:</p><ul><li>Finishes the processing the current message.</li><li>Suspends message processing.</li><li><strong>Stop its children</strong> - See <a href=https://bphenriques.github.io/knowledge-base/concurrency/actor-model/>Actor Model</a>.</li><li>Waits for their termination confirmations and then stops himself.</li></ul><p>How to stop: <code>PoisonPill</code> (<code>context.stop(self())</code>) and <code>actorRef ! Kill</code> messages (throw <code>ActorKilledException</code>). They are <strong>not</strong> appropriate to perform a cleanup before shutting down as the Actor does not &ldquo;see&rdquo; those messages (it is handled internally). It is best to use a dedicated message such as <code>StopMeGraciouslyMessage</code>.</p><h3 id=monitor>Monitor
<a class=anchor href=#monitor>#</a></h3><p><em>Dead Watch</em> allows monitoring another actor&rsquo;s termination (regular <code>Terminated</code> message in the <code>receive</code> block).</p><h2 id=failure-handling>Failure Handling
<a class=anchor href=#failure-handling>#</a></h2><p>Akka deals with failures at the level of the individual actor (bulkheading has it only affects that actor).</p><p>Does not throw the message back to the sender (b/c the sender does not know how to handle it). Instead the error is sent to a responsibile entity (e.g., &ldquo;Manager&rdquo;) that determines the required steps to recover.</p><p>When an actor fails, Akka provides two configurable strategies:</p><ul><li><em>OneForOneStrategy</em>: Only the faulty child is affected.</li><li><em>AllForOneStrategy</em>: All children are affected by one faulty child.</li></ul><p>Both are configured with a <code>type Decider = PartialFunction[Throwable, Directive]</code>. If not defined a directive, then the parent is consired faulty. Where <code>Directive</code>:</p><ul><li>Resume: Resume message processing. Use if the state remains valid.</li><li>Restart: Start a new actor in its place and resume, however all childs are stopped (by default unless <code>preRestart</code> hook is changed). It supports max number of retries and within a time limit.</li><li>Stop.</li><li>Escalate: Delegate the decision to the supervisor&rsquo;s parent.</li></ul><p>By default it is <em>OneForOneStrategy</em> with some directives that are too specific to group here and we can check the documentation. In short, by default, the actor will be restarted. In any case, message processing is suspended.</p><ul><li>All descendants of the actor are suspended.</li><li>The actor&rsquo;s parent handles the failure.</li></ul><p>Proper tuning leads to a self-healing system. Some exceptions are worth stopping the actor while others are worth recovering.</p><h3 id=full-lifecycle>Full Lifecycle
<a class=anchor href=#full-lifecycle>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201012_203109screenshot.png></figure><h2 id=ask-vs-tell>Ask vs Tell
<a class=anchor href=#ask-vs-tell>#</a></h2><p>Ask: <code>actorRef ? Message</code>
Tell: <code>actorRef ! Message</code></p><p>Use Ask when:</p><ul><li>Bridging non-actor code to actor-code (e.g., bridging with HTTP controllers ?).</li><li>We are expecting a response within a timeout. In this case we use <code>actorRef ? Message pipeTo self</code> which in turn will will handle the response, e.g., <code>val receive: Receive = { case MessageResponse => stuff }</code>.</li></ul><p>Use tell when:</p><ul><li>We do not care about the response.</li></ul><h2 id=router><span class="org-todo todo TODO">TODO</span> Router
<a class=anchor href=#router>#</a></h2><p>It is something I have more questions about :thinking:</p><h2 id=akka-streams>Akka Streams
<a class=anchor href=#akka-streams>#</a></h2><p>Use cases: live-data, ETL systems, streaming.</p><ul><li>It is more efficient to consume asyncronously.</li><li>Avoid flooding a slow consumer (backpressure).</li></ul><p>Initiative to provide a standard for async stream processing with non-blocking backpressure.</p><p>Components of a Reactive Stream:</p><ul><li>Publisher: Publishes data to stream</li><li>Subscriber: Consumes data from the stream.</li><li>Processor: Acts as both a publisher and a subscriber, obeying the contract for each.</li><li>Subscription: Connects a subscriber to a publisher to initiate a message flow.</li></ul><p>Streams of data are Messages that will be consumed by actors.</p><h3 id=how>How
<a class=anchor href=#how>#</a></h3><p>Data flows through a chain of processing stages. Each stage has zero or more inputs/outputs depending on the type. By default these stages run <strong>sync</strong> inside a single actor but can also be configured to run asyncronously in separate actors.</p><h4 id=linear-streams>Linear Streams
<a class=anchor href=#linear-streams>#</a></h4><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201013_222125screenshot.png></figure><ul><li>Sources: the source of the data in the stream. E.g., CSV.</li><li>Sinks: the &ldquo;destination&rdquo; for the data. E.g., CSV file.</li><li>Flows: Transformations. E.g., Concatenate columns.</li><li>Runnable Graph: A stream where all the inputs and outputs are connected.</li></ul><p>Each stage can be run sync or async. In most cases the order is preserved.</p><p>Backpressure is propagated downstream stages to upstream.</p><ul><li><p>Source</p><p>Stage with single output: <code>Source[+Out, +Mat]</code>:</p><ul><li><code>Out</code>: The type of each element that is produced.</li><li><code>Mat</code>: Type of the materialized value. Usually <code>NotUsed</code>.</li></ul><p>Source only push data as long as there is demand. The source will have to deal with incoming data until demand resumes (how how largely demands on the use-case).</p><p>E.g., <code>empty</code>, <code>single</code>, <code>repeat</code> (repeat), <code>tick</code> (schedule), from iterables, cycle (same as iterable but repeats), stateful source ~unfold(initial)(fn), from actors, from files, tcp connections (!= data sent through it), java streams.</p></li></ul><ul><li><p>Sink</p><p>Stage with a single input: <code>Sink[-In, +Mat]</code>:</p><ul><li>In: The type of each element that is consumed.</li><li>Mat The type of each element that is produced. E.g., Future[Int].</li></ul><p>It creates backpressure by controlling <em>Demand</em>.</p><p>E.g., ignore, foreach (pure side effects as it does not return values), head/last, headOption/lastOption, seq (materialized all elements), stateful sinks such as fold and reduce, actorRef (no backpressure mechanism), actorRefAck (provides backpressure), FileIO.toPath, StreamConverts.fromJavaStream.</p><p>Note that if the stream is infinite, these sinks may never complete.</p></li></ul><ul><li><p>Flows</p><p>Single input and single output: <code>Flow[-In, +Out, +Mat]</code>.</p><p>Acts both as producer and consumer therefore it propagates demand to the producer as well propagating (and transforming) messages produced to downstream stages.</p><p>E.g., map, mapAsync(Parallelism) that still guarantees order, mayAsyncUnordered, mapConcat (similar to flatMap but not the same), grouped, sliding, fold, scan (emits each new computed result), filter, collect, limit by time using takeWithin(Duration), dropWithin(Duration), groupedWithin(Number, Duration), zip, flatMapConcat (similar mapConcat but operates on Sources rather than iterables), flatMapMerge (similar to flatMapContact but the substreams are consumed consumed therefore order is not guaranteed), buffer(size, strategy) (smooth incosistencies in the flow rate), for slow consumers/producers we have expand (extrapolate for slow producers), batch (for slow consumer) and conflate (create summary of the elements when the producer is faster), log.</p><p>Some of these operations are directly accessible from <code>Source</code> and does not require additional typing.</p></li></ul><ul><li><p>Runnable Graphs</p><p>Connects source, flows, sinks so that data can start flowing.</p><p>E.g.,:</p><ul><li>to: materializes the value from left to right. - Returns Cancellable.</li><li>toMat: Transform/combine materialized values: <code>source.viaMat(flow)(Keep.right).to(sink).run()</code> - Returns NotUsed.</li><li>viaMat: Similar but operates on a flow as opposed to sink - Returns Future[Done].</li></ul></li></ul><ul><li><p>Fault Tolerancy.</p><p>Default strategy is to stop processing the stream and can be overriden within the <code>ActorMaterializer</code> by passing a decider that given an exception it either decides:</p><ul><li>Stop: terminate with an error.</li><li>Resume: Drop the failing element.</li><li>Restart: The element is dropped and the stream continues after restarting the stage. Any state acumulated by that stage will be cleared.</li></ul><p>Each stage can be fine-tuned to choose a dispatchet, bufferSize, log levels and supervision.</p><p>Sometimes errors are recoverable which is a <code>Throwable -> T</code>.</p></li></ul><ul><li><p>Graphs</p><p>Introduces Junctions which take multiple inputs and multiple outputs. Basic ones are:</p><ul><li>Fan in: N inputs + 1 output. E.g., Merge (random selects from the inputs), MergePreferred (give one input higher priority), ZipWith (arity N), Zip (arity 2), Concat.</li><li>Fan out: 1 input + N outputs. E.g., Broadcast, Balance (to just one of the outputs), UnzipWithin to for example split a tuple to send to the outputs, UnZip splits a tuple[A, B] onto 2 streams A and B.</li></ul><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201014_220602screenshot.png></figure></li></ul><ul><li><p>Fusion</p><p>Until now all of this runs syncronously as Akka &ldquo;fuses&rdquo; all stages onto a single syncronous one.</p><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201014_224503screenshot.png></figure><p>When fused on, buffers are not present in each stage. When turned-off each stage has a dedicated buffer once we start processing stages asyncronously.</p><p>We can disable fusing for everything however we can be more selective: <code>Source(1 to 10).async.runForEach(println)</code>. This creates overhead of:</p><ul><li>Actors.</li><li>Mailboxes.</li><li>Buffers.</li></ul><p>It is not a magic bullet. Performance gain/loss depends on the use-case.</p><p>Fusion optimization principles is: &ldquo;insert an async boundary to bisect the stream into two subsections of roughly equal processing time.&rdquo;. In other words, check at the current pipeline where the stages can be split so that they can be performed in paralell and joined almost at the same time. This implies looking at Grafana, analyse each stage and compare with the stream graph we have.</p><p>Lesson: Do not multitask on your computer while you are doing benchmarks :P This affected the exercises throughput by <em>a lot</em>.</p></li></ul><h4 id=graphs>Graphs
<a class=anchor href=#graphs>#</a></h4><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201013_222507screenshot.png></figure><p>Linear streams are most of the times sufficient. However, there are some cases where there are multiple inputs and outputs. Leading to additional components:</p><ul><li>Junctions: Branch points in the stream (e.g., fan-in, fan-out).</li></ul><p>All the introduced components are immutable and can be reused in different scenarios as they solely contain instructions to do <em>something</em> with the data.</p><h4 id=example>Example
<a class=anchor href=#example>#</a></h4><p>Simple stream:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=color:#a6e22e>Source</span><span style=color:#f92672>(</span><span style=color:#ae81ff>1</span> to <span style=color:#ae81ff>10</span><span style=color:#f92672>)</span>                  <span style=color:#75715e>// source
</span><span style=color:#75715e></span>  <span style=color:#f92672>.</span>via<span style=color:#f92672>(</span><span style=color:#a6e22e>Flow</span><span style=color:#f92672>[</span><span style=color:#66d9ef>Int</span><span style=color:#f92672>].</span>map<span style=color:#f92672>(</span><span style=color:#66d9ef>_</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span><span style=color:#f92672>))</span>     <span style=color:#75715e>// stage
</span><span style=color:#75715e></span>  <span style=color:#f92672>.</span>to<span style=color:#f92672>(</span><span style=color:#a6e22e>Sink</span><span style=color:#f92672>.</span>foreach<span style=color:#f92672>(</span>println<span style=color:#f92672>))</span>     <span style=color:#75715e>// sink
</span><span style=color:#75715e></span>  <span style=color:#f92672>.</span>run                           <span style=color:#75715e>// materialize the graph
</span></code></pre></div><h3 id=backpressure>Backpressure
<a class=anchor href=#backpressure>#</a></h3><figure><img src=https://bphenriques.github.io/knowledge-base/ox-hugo/_20201013_221335screenshot.png></figure><ul><li><p>pull/push mechanism.</p><p>Subscribers signal demand that is sent upstream via subscription. Publishers then push data (if available), this way publisher does not send more information than that it was demanded.</p></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div><a class="flex align-center" href=https://github.com/bphenriques/knowledge-base/edit/master/org/uncategorized/akka.org target=_blank rel=noopener><img src=https://bphenriques.github.io/knowledge-base/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#akka>Akka</a></li><li><a href=#akka-cluster>Akka Cluster</a></li><li><a href=#akka-cluster-aware-routers>Akka Cluster Aware Routers</a></li><li><a href=#akka-cluster-sharding>Akka Cluster Sharding</a></li><li><a href=#akka-distributed-data>Akka Distributed Data</a><ul><li><a href=#other>Other</a></li></ul></li><li><a href=#akka-address>Akka Address</a></li><li><a href=#joining-a-cluster>Joining a Cluster</a></li><li><a href=#akka-cluster-management>Akka Cluster Management</a><ul><li><a href=#akka-discovery>Akka Discovery</a></li><li><a href=#akka-cluster-bootstrap>Akka Cluster Bootstrap</a></li><li><a href=#health-check-endpoints>Health Check Endpoints</a></li></ul></li><li><a href=#communication>Communication</a></li><li><a href=#network-partitions>Network Partitions</a></li><li><a href=#split-brain>Split Brain</a><ul><li><a href=#when-using-sharding-or-singleton-for-data-consistency>When using sharding or singleton for data consistency</a></li></ul></li><li><a href=#lighbend-split-brain-resolver>Lighbend Split Brain Resolver</a><ul><li><a href=#static-quorum>Static Quorum</a></li><li><a href=#keep-majority>Keep Majority</a></li><li><a href=#keep-oldest>Keep Oldest</a></li><li><a href=#keep-referee>Keep Referee</a></li><li><a href=#down-allows>Down Allows</a></li><li><a href=#lease-majority>Lease Majority</a></li><li><a href=#some-edge-cases>Some Edge Cases</a></li></ul></li><li><a href=#orphaned-node>Orphaned Node</a></li><li><a href=#cluster-singleton><span class="org-todo todo TODO">TODO</span> Cluster Singleton</a></li><li><a href=#akka-cluster-sharding>Akka Cluster Sharding</a><ul><li><a href=#entities>Entities</a></li><li><a href=#shard>Shard</a></li><li><a href=#shard-region>Shard Region</a></li><li><a href=#shard-coordinator>Shard Coordinator</a></li></ul></li><li><a href=#handling-messages-asyncronously>Handling Messages Asyncronously</a></li><li><a href=#passivation>Passivation</a></li><li><a href=#rebalancing>Rebalancing</a><ul><li><a href=#remember-entities>Remember Entities</a></li></ul></li><li><a href=#semantics>Semantics</a></li><li><a href=#akka-actor-lifecycle>Akka Actor Lifecycle</a><ul><li><a href=#monitor>Monitor</a></li></ul></li><li><a href=#failure-handling>Failure Handling</a><ul><li><a href=#full-lifecycle>Full Lifecycle</a></li></ul></li><li><a href=#ask-vs-tell>Ask vs Tell</a></li><li><a href=#router><span class="org-todo todo TODO">TODO</span> Router</a></li><li><a href=#akka-streams>Akka Streams</a><ul><li><a href=#how>How</a></li><li><a href=#backpressure>Backpressure</a></li></ul></li></ul></nav></aside></main></body></html>